+++
title = "Learning From Data Final"
date = "2023-11-10T21:59:16-08:00"
# description = ""

draft = true
tags = ["notes", "ml"]
+++


[PDF of problems](https://work.caltech.edu/homework/final.pdf)

[Code Repository](https://github.com/lienzhuzhu/lfd)


<h3>
1. [e]
</h3>

Use the formula for the transform of a $2$-dimensional feature space to one of dimension $Q$.

$$
\begin{aligned}
\frac{Q(Q+3)}{2} &= \frac{10(13)}{2} \\\ \\\
    &= 65
\end{aligned}
$$



<h3>
2. [d]
</h3>

Consider a target function shaped like a bell curve, where points with extreme features were labeled -1 and more moderate points were labeled +1.

Logistic regression wouldn't be an appropriate model to include in any hypothesis set to learn this target, but for this question we consider the average $g^{\mathcal{D}}$. It's plausible the average would look nothing like a logistic regression curve.



<h3>
3. [d]
</h3>

We know overfitting occurs when we pick a hypothesis such that $E_{in}$ is minimized but we see a larger $E_{out}$ when that hypothesis is used out of sample, compared to other hypotheses. Using this fact as our guiding star, let's go through the answer choices.

[a]. In order for us to have picked on hypothesis over another, it must be the case that one of them had a lower $E_{in}$.

[b]. We must also be able to say that some other hypothesis has lower generalization error than the one selected.

[c]. We must have some estimate of $E_{out}$ for our hypothesis and some other hypothesis that we should have picked, but no time for regrets. This means even if both $E_{out}$ values are equal, because the hypotheses must have had different $E_{in}$'s for us to have selected the poor hypothesis, $E_{out} - E_{in}$ must be different for the 2 hypotheses.

[e]. We must have a choice between 2 or more hypotheses in order to say we overfit the data by selecting some hypothesis. Overfitting is like admitting you had a choice between 2 women to make your girlfriend and you picked the one who was deceptively sweet at first (low $E_{in}$) but not very sweet once you pick her (high $E_{out}$). Looking back you realize you should have picked the one who didn't put up false pretenses (slightly higher $E_{in}$) and would treat you like a king (low $E_{out}$).

After analyzing incorrect answer choices, we can make a statement about the correct answer choice.

[d]. Comparing $E_{out}-E_{in}$ values is not a principled indicator for overfitting. We may think that larger $E_{out}-E_{in}$ value corresponds to overfitting, but we might imagine a case where the hypothesis we pick has $E_{in} = 0$ and $E_{out} = 0.25$, while some other hypothesis has $E_{in} = 0.50$ and $E_{out} = 0.60$. Then if we go by difference, the other hypothesis looks better, but in reality it has higher out of sample error.

Using the difference between out of sample and in sample error would not clue us in to detect overfitting, since the hypothesis we pick may very well be the best one for that data set and available hypotheses, but have a larger difference.



<h3>
4. [d]
</h3>

Stochastic noise captures the probabilistic essence of real-world target functions, shifting the notion of target function to target _distribution_. It's what allows the same input point to have a different label, for instance two credit card applicants with identical application details, but only one is approved while the other is declined.

It does not relate to the hypothesis set.

Why not the other options?

[a]. There is always inseparable deterministic and stochastic noise for real-world problems.

[b]. Deterministic noise depends on the hypothesis set very much. More complex hypotheses would have less deterministic noise than simple hypotheses when fitting a complex target.

[c]. Deterministic noise captures the intricacies of the target function that cannot be approximated by the hypothesis set.

[e]. Stochastic noise is generated by the probabilistic target distribution, that is why it is a target _distribution_ and not a target _function_.



<h3>
5. [a]
</h3>

If $\vec{w}\_{lin}$ is in the constrained hypothesis set $\mathcal{H}(C)$, then there is no need for regularization and $\vec{w}\_{reg} = \vec{w}_{lin}$.


<h3>
6. [b]
</h3>

Being able to define an augmented error allows us to solve an unconstrained optimization problem.

$$
\vec{w}_{reg} = (Z^TZ + \lambda{I})^{-1}Z^T\vec{y}
$$

Why the other's are incorrect:

[a]. The reverse is true, hard order constraints can be written as soft order constraints using extreme $\gamma$'s on each weight.

[c]. I'm not aware of any relation to the VC dimension besides the fact that regularization can decrease the VC dimension since we shift the notion to effective number of parameters. Validation is used to determine constraints.

[d]. Regularization concedes increases in $E_{in}$ for decreases in $E_{out}$.
